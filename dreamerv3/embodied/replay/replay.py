import threading
import time
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor
from functools import partial as bind

import embodied
import numpy as np

from . import chunk as chunklib
from . import limiters
from . import selectors


class Replay:
    def __init__(
        self,
        length,
        capacity=None,
        directory=None,
        chunksize=1024,
        min_size=1,
        samples_per_insert=None,
        tolerance=1e4,
        seed=0,
    ):
        assert not capacity or min_size <= capacity

        self.length = length
        self.capacity = capacity
        self.directory = directory and embodied.Path(directory)
        self.chunksize = chunksize

        self.sampler = selectors.Uniform(seed)
        if samples_per_insert:
            self.limiter = limiters.SamplesPerInsert(
                samples_per_insert, tolerance, min_size
            )
        else:
            self.limiter = limiters.MinSize(min_size)

        self.chunks = {}
        self.refs = {}
        self.refs_lock = threading.RLock()

        self.items = {}
        self.fifo = deque()
        self.itemid = 0

        self.current = {}
        self.streams = defaultdict(deque)
        self.rwlock = embodied.RWLock()

        if self.directory:
            self.directory.mkdirs()
            self.workers = ThreadPoolExecutor(8, "replay_saver")
            self.promises = {}

        self.metrics = {
            "samples": 0,
            "sample_wait_dur": 0,
            "sample_wait_count": 0,
            "inserts": 0,
            "insert_wait_dur": 0,
            "insert_wait_count": 0,
        }

    def __len__(self):
        return len(self.items)

    def stats(self):
        ratio = lambda x, y: x / y if y else np.nan
        m = self.metrics
        chunk_nbytes = sum(x.nbytes for x in list(self.chunks.values()))
        stats = {
            "items": len(self.items),
            "chunks": len(self.chunks),
            "streams": len(self.streams),
            "ram_gb": chunk_nbytes / (1024**3),
            "inserts": m["inserts"],
            "samples": m["samples"],
            "replay_ratio": ratio(self.length * m["samples"], m["inserts"]),
            "insert_wait_avg": ratio(m["insert_wait_dur"], m["inserts"]),
            "insert_wait_frac": ratio(m["insert_wait_count"], m["inserts"]),
            "sample_wait_avg": ratio(m["sample_wait_dur"], m["samples"]),
            "sample_wait_frac": ratio(m["sample_wait_count"], m["samples"]),
        }
        for key in self.metrics:
            self.metrics[key] = 0
        return stats

    def clear(self):
        self.chunks.clear()
        self.refs.clear()
        self.items.clear()
        self.fifo.clear()
        self.itemid = 0
        self.current.clear()
        self.streams.clear()

    @embodied.timer.section("replay_add")
    def add(self, step, worker=0):
        with self.rwlock.reading:
            step = {k: v for k, v in step.items() if not k.startswith("log_")}
            step = {k: np.asarray(v) for k, v in step.items()}
            # step['id'] = np.asarray(embodied.uuid(step.get('id')))

            if worker not in self.current:
                chunk = chunklib.Chunk(self.chunksize)
                with self.refs_lock:
                    self.refs[chunk.uuid] = 1
                self.chunks[chunk.uuid] = chunk
                self.current[worker] = (chunk.uuid, 0)

            chunkid, index = self.current[worker]
            stream = self.streams[worker]
            chunk = self.chunks[chunkid]
            assert chunk.length == index, (chunk.length, index)
            chunk.append(step)
            assert chunk.length == index + 1, (chunk.length, index + 1)
            stream.append((chunkid, index))
            with self.refs_lock:
                self.refs[chunkid] += 1

            index += 1
            if index < chunk.size:
                self.current[worker] = (chunkid, index)
            else:
                self._complete(chunk, worker)
            assert len(self.streams) == len(self.current)

            if len(stream) >= self.length:
                dur = self._wait(self.limiter.want_insert, "Replay insert is waiting")
                # These increments are not thread safe, so the metrics will be slightly
                # wrong and it's faster than introducing a lock.
                self.metrics["inserts"] += 1
                self.metrics["insert_wait_dur"] += dur
                self.metrics["insert_wait_count"] += int(dur >= 0.001)
                chunkid, index = stream.popleft()
                self._insert(chunkid, index)

    @embodied.timer.section("replay_sample")
    def _sample(self):
        dur = self._wait(self.limiter.want_sample, "Replay sample is waiting")
        self.limiter.sample()
        # These increments are not thread safe, so the metrics will be slightly
        # wrong and it's faster than introducing a lock.
        self.metrics["samples"] += 1
        self.metrics["sample_wait_dur"] += dur
        self.metrics["sample_wait_count"] += int(dur >= 0.001)
        while True:
            with embodied.timer.section("draw"):
                itemid = self.sampler()
            with embodied.timer.section("lookup"):
                # Look up the item or repeat if it was already removed in the meantime.
                try:
                    chunkid, index = self.items[itemid]
                    chunk = self.chunks[chunkid]
                    break
                except KeyError:
                    continue
        available = chunk.length - index
        if available >= self.length:
            with embodied.timer.section("slice"):
                seq = chunk.slice(index, self.length)
        else:
            with embodied.timer.section("compose"):
                parts = [chunk.slice(index, available)]
                remaining = self.length - available
                while remaining > 0:
                    chunk = self.chunks[chunk.succ]
                    take = min(remaining, chunk.length)
                    parts.append(chunk.slice(0, take))
                    remaining -= take
                seq = {
                    k: np.concatenate([p[k] for p in parts], 0) for k in parts[0].keys()
                }
        with embodied.timer.section("isfirst"):
            if "is_first" in seq:
                seq["is_first"] = seq["is_first"].copy()
                seq["is_first"][0] = True
        return seq

    def _insert(self, chunkid, index):
        itemid = self.itemid
        self.itemid += 1
        self.items[itemid] = (chunkid, index)
        self.sampler[itemid] = (chunkid, index)
        self.fifo.append(itemid)
        self.limiter.insert()
        while self.capacity and len(self.items) > self.capacity:
            self._remove()

    def _remove(self):
        self.limiter.remove()
        itemid = self.fifo.popleft()
        del self.sampler[itemid]
        chunkid, index = self.items.pop(itemid)
        with self.refs_lock:
            self.refs[chunkid] -= 1
            if self.refs[chunkid] < 1:
                del self.refs[chunkid]
                chunk = self.chunks.pop(chunkid)
                if chunk.succ in self.refs:
                    self.refs[chunk.succ] -= 1

    def dataset(self, batch=None):
        if batch:
            while True:
                seqs = []
                for _ in range(batch):
                    seqs.append(self._sample())
                stacked = {
                    k: np.stack([seq[k] for seq in seqs]) for k in seqs[0].keys()
                }
                yield stacked
        else:
            while True:
                yield self._sample()

    @embodied.timer.section("replay_save")
    def save(self, wait=False):
        if not self.directory:
            return
        with self.rwlock.writing:
            [x.result() for x in list(self.promises.values())]
            for worker, (chunkid, _) in self.current.items():
                chunk = self.chunks[chunkid]
                if chunk.length > 0:
                    self._complete(chunk, worker)
            wait and [x.result() for x in list(self.promises.values())]

    @embodied.timer.section("replay_load")
    def load(self, data=None, directory=None, amount=None):
        assert data is None
        directory = directory or self.directory
        amount = amount or self.capacity or np.inf
        if not directory:
            return
        revsorted = lambda x: list(reversed(sorted(list(x))))
        directory = embodied.Path(directory)
        names_loaded = revsorted(x.filename for x in list(self.chunks.values()))
        names_ondisk = revsorted(x.name for x in directory.glob("*.npz"))
        names_ondisk = [x for x in names_ondisk if x not in names_loaded]
        if not names_ondisk:
            return

        numitems = self._numitems(names_loaded + names_ondisk)
        uuids = [embodied.uuid(x.split("-")[1]) for x in names_ondisk]
        total = 0
        numchunks = 0
        for uuid in uuids:
            numchunks += 1
            total += numitems[uuid]
            if total >= amount:
                break

        load = bind(chunklib.Chunk.load, error="none")
        filenames = [directory / x for x in names_ondisk[:numchunks]]

        with ThreadPoolExecutor(16, "replay_loader") as pool:
            chunks = [x for x in pool.map(load, filenames) if x]

        # We need to recompute the number of items per chunk now because some
        # chunks be corrupted and thus not available.
        # numitems = self._numitems(chunks + list(self.chunks.values()))
        numitems = self._numitems(chunks)

        with self.rwlock.writing:
            with self.refs_lock:
                for chunk in chunks:
                    self.chunks[chunk.uuid] = chunk
                    self.refs[chunk.uuid] = 0
                for chunk in reversed(chunks):
                    amount = numitems[chunk.uuid]
                    self.refs[chunk.uuid] += amount
                    if chunk.succ in self.refs:
                        self.refs[chunk.succ] += 1
                    for index in range(amount):
                        self._insert(chunk.uuid, index)

    @embodied.timer.section("complete_chunk")
    def _complete(self, chunk, worker):
        succ = chunklib.Chunk(self.chunksize)
        with self.refs_lock:
            self.refs[chunk.uuid] -= 1
            self.refs[succ.uuid] = 2
        self.chunks[succ.uuid] = succ
        self.current[worker] = (succ.uuid, 0)
        chunk.succ = succ.uuid
        if self.directory:
            (worker in self.promises) and self.promises.pop(worker).result()
            self.promises[worker] = self.workers.submit(chunk.save, self.directory)
        return succ

    def _numitems(self, chunks):
        chunks = [x.filename if hasattr(x, "filename") else x for x in chunks]
        chunks = list(reversed(sorted([embodied.Path(x).stem for x in chunks])))
        times, uuids, succs, lengths = zip(*[x.split("-") for x in chunks])
        uuids = [embodied.uuid(x) for x in uuids]
        succs = [embodied.uuid(x) for x in succs]
        lengths = {k: int(v) for k, v in zip(uuids, lengths)}
        future = {}
        for uuid, succ in zip(uuids, succs):
            future[uuid] = lengths[uuid] + future.get(succ, 0)
        numitems = {}
        for uuid, succ in zip(uuids, succs):
            numitems[uuid] = lengths[uuid] + 1 - self.length + future.get(succ, 0)
        numitems = {k: np.clip(v, 0, lengths[k]) for k, v in numitems.items()}
        return numitems

    def _wait(self, predicate, message, sleep=0.01, notify=1.0):
        # Early exit if rate is not currently limited.
        if predicate(reason=False):
            return 0
        # Wait without messages to avoid creating string objects.
        start = time.time()
        duration = 0
        while duration < notify:
            duration = time.time() - start
            if predicate(reason=False):
                return duration
            time.sleep(sleep)
        # Get the reason once to provide a useful user message.
        allowed, reason = predicate(reason=True)
        if allowed:
            return time.time() - start
        else:
            print(f"{message} ({reason})")
            time.sleep(sleep)
        # Keep waiting without messages to avoid creating string objects.
        while not predicate(reason=False):
            time.sleep(sleep)
        return time.time() - start
